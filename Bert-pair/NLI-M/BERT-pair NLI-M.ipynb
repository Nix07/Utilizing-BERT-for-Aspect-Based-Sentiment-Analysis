{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT-pair NLI-M.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"686e558d20f54fb287057ebc7dedabc3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_749c815441864a1f8b30e244a4e19cee","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_14d2b5e499e3464f85694c676ada3a19","IPY_MODEL_a5296386ee59477eb6b7aec8ea19fa2e"]}},"749c815441864a1f8b30e244a4e19cee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"14d2b5e499e3464f85694c676ada3a19":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1ae4280d851b427ba26e9263c4802861","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1dc29c97f03c42199c81bf832d87e58c"}},"a5296386ee59477eb6b7aec8ea19fa2e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_390d967d92cf4d95b50848bba270e542","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 297kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b3b22385f34941869e88571bfbdc7057"}},"1ae4280d851b427ba26e9263c4802861":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1dc29c97f03c42199c81bf832d87e58c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"390d967d92cf4d95b50848bba270e542":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b3b22385f34941869e88571bfbdc7057":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3a08c24051864f6882e536247b3b3eba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fe34dc9d561b4d5586356181649e8607","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_32a96709e296411cb8eb46ca2e824ed7","IPY_MODEL_16d2ccf2b76b47ff801f4db349ca5378"]}},"fe34dc9d561b4d5586356181649e8607":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"32a96709e296411cb8eb46ca2e824ed7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_138dc29596cf4489a9aba29233dc55cf","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fd5b0bfbaaea4f6bb4e8b03168b5b51f"}},"16d2ccf2b76b47ff801f4db349ca5378":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fe39be5f5d46472aa1822a834a33ab3d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:00&lt;00:00, 881B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_414c16a31e6d4691998d1d7f61229bee"}},"138dc29596cf4489a9aba29233dc55cf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"fd5b0bfbaaea4f6bb4e8b03168b5b51f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fe39be5f5d46472aa1822a834a33ab3d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"414c16a31e6d4691998d1d7f61229bee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3fe57c0e90814f32a307e6b17cc366cd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d89f18d9f87f46ee8496bb7c5fb30681","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f70862fe90e04e08ba6ce920c294fc70","IPY_MODEL_577fa7e5e3e94c56a8f28de2f96c0026"]}},"d89f18d9f87f46ee8496bb7c5fb30681":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f70862fe90e04e08ba6ce920c294fc70":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_674cdb843ff44c46bbd8ca9df73201aa","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7547ff4556054b7887eafc75f61f7b33"}},"577fa7e5e3e94c56a8f28de2f96c0026":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_eaa39876a6b64691af8c824aa4cc0bd9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:10&lt;00:00, 41.3MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b17ab19133ba47f98dcb1191289059ce"}},"674cdb843ff44c46bbd8ca9df73201aa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7547ff4556054b7887eafc75f61f7b33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eaa39876a6b64691af8c824aa4cc0bd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b17ab19133ba47f98dcb1191289059ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"0iwni_X20REP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":685},"executionInfo":{"status":"ok","timestamp":1596385866855,"user_tz":-330,"elapsed":48556,"user":{"displayName":"NIKHIL PRAKASH","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgE64-zyQNQSjSixENWJyhGqao6rzutp-TYuXNn2Q=s64","userId":"07464489639094286985"}},"outputId":"176f553e-7189-46c0-aefd-99a98ab64156"},"source":["# Install dependencies\n","!pip uninstall -y tensorflow\n","!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Uninstalling tensorflow-2.2.0:\n","  Successfully uninstalled tensorflow-2.2.0\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n","\u001b[K     |████████████████████████████████| 778kB 2.7MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 13.7MB/s \n","\u001b[?25hCollecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 13.7MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Collecting tokenizers==0.8.1.rc1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 8.2MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=05c1b1df88c59190031109a2361d691878fcf654b402dedb0d0b659bed240d94\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jg_IJ_vH99tF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":127},"executionInfo":{"status":"ok","timestamp":1596385926036,"user_tz":-330,"elapsed":24702,"user":{"displayName":"NIKHIL PRAKASH","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgE64-zyQNQSjSixENWJyhGqao6rzutp-TYuXNn2Q=s64","userId":"07464489639094286985"}},"outputId":"9134dd01-ed5d-4f3d-a9dc-fd42b11fd0eb"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WFxL89PU0bXV","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import transformers\n","from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n","from torch.optim import lr_scheduler\n","\n","import logging\n","logging.basicConfig(level=logging.ERROR)\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NoIu1VSSE_3U","colab_type":"code","colab":{}},"source":["class SentimentClassifier(nn.Module):\n","  \"\"\"\n","  This class defines the model architecture which is simply a fully-connected\n","  layer on top of a pre-trained BERT model. \n","  \"\"\"\n","\n","  def __init__(self, BERT_MODEL):\n","    super(SentimentClassifier, self).__init__()\n","    self.bert = BertModel.from_pretrained(BERT_MODEL)\n","    self.drop = nn.Dropout(p=0.3)\n","    self.out = nn.Linear(self.bert.config.hidden_size, 3) # Number of output classes = 3\n","\n","  def forward(self, ids, mask, token_type_ids):\n","    last_hidden_state, pooled_output = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids)\n","    output = self.drop(pooled_output)\n","    return self.out(output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LySwsdB7-TxP","colab_type":"code","colab":{}},"source":["class SentiHood:\n","  \"\"\"\n","  This class tokenizes the input text using the pre-trained BERT tokenizer \n","  (wordpiece) and returns the corresponding tensors.\n","  \"\"\"\n","  \n","  def __init__(self, text, auxiliary_sentence, targets, tokenizer, max_len):\n","    self.text = text\n","    self.auxiliary_sentence = auxiliary_sentence\n","    self.tokenizer = tokenizer\n","    self.max_len = max_len\n","    self.targets = targets\n","\n","  def __len__(self):\n","    return len(self.targets)\n","\n","  def __getitem__(self, item):\n","    text = str(self.text[item])\n","    auxiliary_sentence = str(self.auxiliary_sentence[item])\n","    targets = self.targets[item]\n","\n","    text = text + ' ' + auxiliary_sentence\n","\n","    inputs = self.tokenizer.encode_plus(\n","        text,\n","        add_special_tokens = True,\n","        max_length = self.max_len,\n","        pad_to_max_length = True\n","    )\n","\n","    ids = inputs[\"input_ids\"]\n","    mask = inputs[\"attention_mask\"]\n","    token_type_ids = inputs[\"token_type_ids\"]\n","\n","    return {\n","        \"ids\": torch.tensor(ids, dtype=torch.long),\n","        \"mask\": torch.tensor(mask, dtype=torch.long),\n","        \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n","        \"targets\": torch.tensor(targets, dtype=torch.long)\n","    }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NHt02ywTYH2A","colab_type":"code","colab":{}},"source":["def loss_function(outputs, targets):\n","\t\"\"\"\n","\tThis function defines the loss function which is used to train the model, i.e.\n","\tCrossEntropy.\n","\t\"\"\"\n","\n","\t# probability, predicted = torch.max(outputs, 1)\n","\t# print(f\"Predicted = {predicted.cpu().detach().numpy()}\\nTargets = {targets}\")\n","\n","\treturn nn.CrossEntropyLoss(reduction='mean')(outputs, targets)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QXP5g_SKWnW5","colab_type":"code","colab":{}},"source":["def train_loop_function(data_loader, model, optimizer, device):\n","  \"\"\"\n","  This function defines the training loop over the entire training set.\n","  \"\"\"\n","\n","  model.train()\n","\n","  running_loss = 0.0\n","  for bi, d in enumerate(data_loader):\n","    ids = d[\"ids\"]\n","    mask = d[\"mask\"]\n","    token_type_ids = d[\"token_type_ids\"]\n","    targets = d[\"targets\"]\n","\n","    ids = ids.to(device, dtype=torch.long)\n","    mask = mask.to(device, dtype=torch.long)\n","    token_type_ids = token_type_ids.to(device, dtype=torch.long)\n","    targets = targets.to(device, dtype=torch.long)\n","\n","    optimizer.zero_grad()\n","\n","    outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n","    loss = loss_function(outputs, targets)\n","\n","    loss.backward()\n","    optimizer.step()\n","\n","    running_loss += loss.item()\n","    if bi % 10 == 0 and bi!=0:\n","      temp = f'Batch index = {bi}\\tLoss = {running_loss/10}'\n","      print(temp)\n","\n","      f1 = open('/content/drive/My Drive/SentiHood/Bert-pair/NLI-M/Models/' + 'loss.txt', 'a+')\n","      temp = temp + '\\n'\n","      f1.write(temp)\n","      f1.close()\n","\n","      running_loss = 0.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rQ-TATCKXCyR","colab_type":"code","colab":{}},"source":["def eval_loop_function(data_loader, model, device):\n","  \"\"\"\n","  This function defines the evaluation loop over the entire validation set.\n","  It also computes accuracy of the trained model, which is used to select the \n","  best model.\n","  \"\"\"\n","  \n","  model.eval()\n","\n","  corrects = 0\n","  total = 0\n","  for bi, d in enumerate(data_loader):\n","    ids = d[\"ids\"]\n","    mask = d[\"mask\"]\n","    token_type_ids = d[\"token_type_ids\"]\n","    targets = d[\"targets\"]\n","\n","    ids = ids.to(device, dtype=torch.long)\n","    mask = mask.to(device, dtype=torch.long)\n","    token_type_ids = token_type_ids.to(device, dtype=torch.long)\n","    targets = targets.to(device, dtype=torch.long)\n","\n","    outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n","\n","    _, predicted = torch.max(outputs, 1)\n","    total = total + targets.size(0)\n","    corrects = corrects + (predicted==targets).sum().item()\n","\n","    print(f\"bi: {bi}\\tPredicted: {predicted}\\tTargets: {targets}\")\n","\n","  accuracy = corrects / total * 100\n","  f1 = open('/content/drive/My Drive/SentiHood/Bert-pair/NLI-M/Models/' + 'accuracy.txt', 'a+')\n","  temp = f\"Corrects: {corrects}\\tTotal: {total}\\tAccuracy: {accuracy}\\n\"\n","  f1.write(temp)\n","  f1.close()\n","\n","  return accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M83SYeDt0ogD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":311,"referenced_widgets":["686e558d20f54fb287057ebc7dedabc3","749c815441864a1f8b30e244a4e19cee","14d2b5e499e3464f85694c676ada3a19","a5296386ee59477eb6b7aec8ea19fa2e","1ae4280d851b427ba26e9263c4802861","1dc29c97f03c42199c81bf832d87e58c","390d967d92cf4d95b50848bba270e542","b3b22385f34941869e88571bfbdc7057","3a08c24051864f6882e536247b3b3eba","fe34dc9d561b4d5586356181649e8607","32a96709e296411cb8eb46ca2e824ed7","16d2ccf2b76b47ff801f4db349ca5378","138dc29596cf4489a9aba29233dc55cf","fd5b0bfbaaea4f6bb4e8b03168b5b51f","fe39be5f5d46472aa1822a834a33ab3d","414c16a31e6d4691998d1d7f61229bee","3fe57c0e90814f32a307e6b17cc366cd","d89f18d9f87f46ee8496bb7c5fb30681","f70862fe90e04e08ba6ce920c294fc70","577fa7e5e3e94c56a8f28de2f96c0026","674cdb843ff44c46bbd8ca9df73201aa","7547ff4556054b7887eafc75f61f7b33","eaa39876a6b64691af8c824aa4cc0bd9","b17ab19133ba47f98dcb1191289059ce"]},"outputId":"3d120bbe-4a08-40b6-dfb0-bba57034e83b"},"source":["def run():\n","  \"\"\"\n","  This function defines hyperparameters, model and optimizer, loads required\n","  datasets and initiate the training and validation procedures.\n","  \"\"\"\n","\n","  TRAIN_MAX_LEN = 160\n","  VALID_MAX_LEN = 160\n","  TRAIN_BATCH_SIZE = 16\n","  VALID_BATCH_SIZE = 16\n","  EPOCHS = 10\n","  BERT_MODEL = 'bert-base-uncased'\n","  LEARNING_RATE = 3e-5\n","\n","  locations = ['LOCATION1', 'LOCATION2']\n","  aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety','shopping', 'touristy', 'transit-location']\n","\n","  training_set_path = '/content/drive/My Drive/SentiHood/Bert-pair/NLI-M/Datasets/training_set.csv'\n","  validation_set_path = '/content/drive/My Drive/SentiHood/Bert-pair/NLI-M/Datasets/validation_set.csv'\n","\n","  df_train = pd.read_csv(training_set_path)\n","  df_valid = pd.read_csv(validation_set_path)\n","  sentiment_mapping = {\n","      'Positive': 0,\n","      'Negative': 1,\n","      'None': 2\n","  }\n","  df_train['sentiment'] = df_train['sentiment'].map(sentiment_mapping)\n","  df_valid['sentiment'] = df_valid['sentiment'].map(sentiment_mapping)\n","  df_train = df_train.reset_index(drop=True)\n","  df_valid = df_valid.reset_index(drop=True)\n","\n","  tokenizer = transformers.BertTokenizer.from_pretrained(BERT_MODEL)\n","\n","  train_dataset = SentiHood(\n","      text = df_train['text'].values,\n","      auxiliary_sentence = df_train['auxiliary_sentence'],\n","      targets = df_train['sentiment'].values,\n","      tokenizer = tokenizer,\n","      max_len = TRAIN_MAX_LEN\n","  )\n","  print(f\"Training Set: {len(train_dataset)}\")\n","\n","  # Custom sampler to compensate class imbalance in the dataset\n","  # ============================================================================\n","  class_counts = []\n","  for i in range(3):\n","    class_counts.append(df_train[df_train['sentiment']==i].shape[0])\n","  print(f\"Class Counts: {class_counts}\")\n","  \n","  num_samples = sum(class_counts)\n","  labels = df_train['sentiment'].values\n","\n","  class_weights = []\n","  for i in range(len(class_counts)):\n","    if class_counts[i] != 0:\n","      class_weights.append(num_samples/class_counts[i])\n","    else:\n","      class_weights.append(0)\n","\n","  weights = [class_weights[labels[i]] for i in range(int(num_samples))]\n","  sampler = torch.utils.data.sampler.WeightedRandomSampler(torch.DoubleTensor(weights), int(num_samples))\n","  # ============================================================================\n","\n","  train_data_loader = torch.utils.data.DataLoader(\n","      train_dataset,\n","      batch_size = TRAIN_BATCH_SIZE,\n","      shuffle = False,\n","      sampler = sampler\n","  )\n","\n","  valid_dataset = SentiHood(\n","      text = df_valid['text'].values,\n","      auxiliary_sentence = df_train['auxiliary_sentence'],\n","      targets = df_valid['sentiment'].values,\n","      tokenizer = tokenizer,\n","      max_len = VALID_MAX_LEN\n","  )\n","  print(f\"Validation Set: {len(valid_dataset)}\")\n","\n","  valid_data_loader = torch.utils.data.DataLoader(\n","      valid_dataset,\n","      batch_size = VALID_BATCH_SIZE,\n","      shuffle = False\n","  )\n","\n","  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","  print(f\"Device: {device}\")\n","\n","  model = SentimentClassifier(BERT_MODEL)\n","  model = model.to(device)\n","\n","  num_train_steps = int(len(train_dataset) / TRAIN_BATCH_SIZE * EPOCHS)\n","  optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n","\n","  scheduler = lr_scheduler.StepLR(\n","      optimizer,\n","      step_size = 1,\n","      gamma = 0.8\n","  )\n","\n","  for epoch in range(EPOCHS):\n","    train_loop_function(data_loader=train_data_loader, model=model, optimizer=optimizer, device=device)\n","    accuracy = eval_loop_function(data_loader=valid_data_loader, model=model, device=device)\n","\n","    print(f\"\\nEpoch = {epoch}\\tAccuracy Score = {accuracy}\")\n","    print(f\"Learning Rate = {scheduler.get_lr()[0]}\\n\")\n","\n","    scheduler.step()\n","\n","    torch.save(model, '/content/drive/My Drive/SentiHood/Bert-pair/NLI-M/Models/' + str(epoch) + '.bin')\n","\n","if __name__ == \"__main__\":\n","  run()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"686e558d20f54fb287057ebc7dedabc3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Training Set: 45024\n","Class Counts: [2474, 921, 41629]\n","Validation Set: 11244\n","Device: cuda:0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3a08c24051864f6882e536247b3b3eba","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3fe57c0e90814f32a307e6b17cc366cd","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Batch index = 10\tLoss = 1.2579200267791748\n","Batch index = 20\tLoss = 1.0927840650081635\n","Batch index = 30\tLoss = 1.0368426203727723\n","Batch index = 40\tLoss = 0.9834808886051178\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ksw8gx2tq5fz","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}