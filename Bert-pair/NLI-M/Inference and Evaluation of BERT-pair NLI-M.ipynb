{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Inference and Evaluation of BERT-pair NLI-M.ipynb","provenance":[],"collapsed_sections":["LACVADTH_U8N","qG4vUkDMGtZ6","HzING8oSa24-","hHUu0aX4poUu"],"authorship_tag":"ABX9TyMIPsqnXmv06KCv8KsUoWxv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"aa09d29845804b6b8f8fd8b5a56a7143":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_72cb7910de5e4230a9e9d6de859ae8f0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0dea047cef9b481cb9a86a7bf50c4447","IPY_MODEL_7253988a719044ecae30c52b6990ad24"]}},"72cb7910de5e4230a9e9d6de859ae8f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0dea047cef9b481cb9a86a7bf50c4447":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_33cd46c8225a4484a2472c20dd50fce8","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6404a5f922aa4afa9125abba1b37538a"}},"7253988a719044ecae30c52b6990ad24":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_19866de1e56341f9945d736857fe93af","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 575kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0e3a709ad09d4e8cb9061978f48d3d2f"}},"33cd46c8225a4484a2472c20dd50fce8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6404a5f922aa4afa9125abba1b37538a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"19866de1e56341f9945d736857fe93af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0e3a709ad09d4e8cb9061978f48d3d2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"33df444fb9204b16847a62ecc46f9f0d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_523ef603903944c99b0aaf28dd51f33e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c7a7bbea4ec541919b389eb2bb984484","IPY_MODEL_6af7380e5b4f4687860c048bfababc35"]}},"523ef603903944c99b0aaf28dd51f33e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c7a7bbea4ec541919b389eb2bb984484":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_547375b67e9c4a9dba4aecfb11a92301","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2007565108ab4012aae8f98348b0b373"}},"6af7380e5b4f4687860c048bfababc35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d38aa1b16d1e4eee9faf96235e1d1808","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 763kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8cfb23cedccb4dca918dd71595b2a464"}},"547375b67e9c4a9dba4aecfb11a92301":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2007565108ab4012aae8f98348b0b373":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d38aa1b16d1e4eee9faf96235e1d1808":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8cfb23cedccb4dca918dd71595b2a464":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"hIANK2Rn_AS2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":649},"executionInfo":{"status":"ok","timestamp":1596462719293,"user_tz":-330,"elapsed":46117,"user":{"displayName":"NIKHIL PRAKASH","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgE64-zyQNQSjSixENWJyhGqao6rzutp-TYuXNn2Q=s64","userId":"07464489639094286985"}},"outputId":"43b49b51-6d83-4846-b63d-5ac182e19578"},"source":["# Install dependencies\n","!pip uninstall -y tensorflow\n","!pip install transformers"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Uninstalling tensorflow-2.2.0:\n","  Successfully uninstalled tensorflow-2.2.0\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n","\u001b[K     |████████████████████████████████| 778kB 3.5MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 9.7MB/s \n","\u001b[?25hCollecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 16.5MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Collecting tokenizers==0.8.1.rc1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 29.6MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=9d940066ac0fa11b6482b2717248a88ffcae8131d430d3d38244d6c001b7cb88\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0uIEvh0A_FUk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1596462752353,"user_tz":-330,"elapsed":18618,"user":{"displayName":"NIKHIL PRAKASH","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgE64-zyQNQSjSixENWJyhGqao6rzutp-TYuXNn2Q=s64","userId":"07464489639094286985"}},"outputId":"7713a73d-69a4-46cd-a8e1-5b0efe69516b"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GK_-dM26_TGi","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596462757304,"user_tz":-330,"elapsed":5244,"user":{"displayName":"NIKHIL PRAKASH","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgE64-zyQNQSjSixENWJyhGqao6rzutp-TYuXNn2Q=s64","userId":"07464489639094286985"}}},"source":["import json\n","import torch\n","import torch.nn as nn\n","import pandas as pd\n","import numpy as np\n","import transformers\n","from tqdm import tqdm\n","from sklearn.metrics import f1_score, accuracy_score\n","from transformers import BertModel, BertTokenizer\n","\n","import logging\n","logging.basicConfig(level=logging.ERROR)\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"VGTic4EP_XSG","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596462757314,"user_tz":-330,"elapsed":4847,"user":{"displayName":"NIKHIL PRAKASH","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgE64-zyQNQSjSixENWJyhGqao6rzutp-TYuXNn2Q=s64","userId":"07464489639094286985"}}},"source":["class SentimentClassifier(nn.Module):\n","  \"\"\"\n","  This class defines the model architecture which is simply a fully-connected\n","  layer on top of a pre-trained BERT model. \n","  \"\"\"\n","\n","  def __init__(self, BERT_MODEL):\n","    super(SentimentClassifier, self).__init__()\n","    self.bert = BertModel.from_pretrained(BERT_MODEL)\n","    self.drop = nn.Dropout(p=0.3)\n","    self.out = nn.Linear(self.bert.config.hidden_size, 3) # Number of output classes = 3\n","\n","  def forward(self, ids, mask, token_type_ids):\n","    last_hidden_state, pooled_output = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids)\n","    output = self.drop(pooled_output)\n","    return self.out(output)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LACVADTH_U8N","colab_type":"text"},"source":["# Inference on BERT-pair NLI-M"]},{"cell_type":"code","metadata":{"id":"hDO650jp_Z7X","colab_type":"code","colab":{}},"source":["class SentiHood:\n","  \"\"\"\n","  This class tokenizes the input text using the pre-trained BERT tokenizer \n","  (wordpiece) and returns the corresponding tensors.\n","  \"\"\"\n","  \n","  def __init__(self, opinions_id, text, auxiliary_sentence, targets, tokenizer, max_len):\n","    self.opinions_id = opinions_id\n","    self.text = text\n","    self.auxiliary_sentence = auxiliary_sentence\n","    self.tokenizer = tokenizer\n","    self.max_len = max_len\n","    self.targets = targets\n","\n","  def __len__(self):\n","    return len(self.targets)\n","\n","  def __getitem__(self, item):\n","    opinions_id = self.opinions_id[item]\n","    text = str(self.text[item])\n","    auxiliary_sentence = str(self.auxiliary_sentence[item])\n","    targets = self.targets[item]\n","\n","    text = text + ' ' + auxiliary_sentence\n","\n","    inputs = self.tokenizer.encode_plus(\n","        text,\n","        add_special_tokens = True,\n","        max_length = self.max_len,\n","        pad_to_max_length = True\n","    )\n","\n","    ids = inputs[\"input_ids\"]\n","    mask = inputs[\"attention_mask\"]\n","    token_type_ids = inputs[\"token_type_ids\"]\n","\n","    return {\n","        \"ids\": torch.tensor(ids, dtype=torch.long),\n","        \"mask\": torch.tensor(mask, dtype=torch.long),\n","        \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n","        \"targets\": torch.tensor(targets, dtype=torch.long),\n","        \"opinions_id\": torch.tensor(opinions_id, dtype=torch.long)\n","    }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tc_tUUJABEVB","colab_type":"code","colab":{}},"source":["def infer_loop_function(data_loader, model, device):\n","  \"\"\"\n","  This function performs the inference on testing sets and stores the predicted\n","  values.\n","  \"\"\"\n","\n","  model.eval()\n","\n","  df_pred = pd.DataFrame({\"id\": [], \"predicted\": [], \"actual\": []})\n","\n","  ii = 0\n","  for bi, d in tqdm(enumerate(data_loader), total=len(data_loader), ncols=80):\n","    opinions_id = d[\"opinions_id\"]\n","    ids = d[\"ids\"]\n","    mask = d[\"mask\"]\n","    token_type_ids = d[\"token_type_ids\"]\n","    targets = d[\"targets\"]\n","\n","    opinions_id = opinions_id.to(device, dtype=torch.long)\n","    ids = ids.to(device, dtype=torch.long)\n","    mask = mask.to(device, dtype=torch.long)\n","    token_type_ids = token_type_ids.to(device, dtype=torch.long)\n","    targets = targets.to(device, dtype=torch.long)\n","\n","    outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n","    _, predicted = torch.max(outputs, 1)\n","    \n","    predicted = predicted.detach().cpu().numpy()\n","    targets = targets.detach().cpu().numpy()\n","    opinions_id = opinions_id.detach().cpu().numpy()\n","\n","    for k in range(len(predicted)):\n","      df_pred.loc[ii] = [str(opinions_id[k]), str(predicted[k]), str(targets[k])]\n","      ii += 1\n","\n","    df_pred.to_csv('/content/drive/My Drive/SentiHood/Bert-pair/NLI-M/PredictedValues.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xalt3-vB_doq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["aa09d29845804b6b8f8fd8b5a56a7143","72cb7910de5e4230a9e9d6de859ae8f0","0dea047cef9b481cb9a86a7bf50c4447","7253988a719044ecae30c52b6990ad24","33cd46c8225a4484a2472c20dd50fce8","6404a5f922aa4afa9125abba1b37538a","19866de1e56341f9945d736857fe93af","0e3a709ad09d4e8cb9061978f48d3d2f"]},"outputId":"0b8d7cb2-fcec-48a1-a5e9-38a3291ca8e7"},"source":["def run():\n","  \"\"\"\n","  This function defines the necessary hyperparameters and models. It also \n","  loads and tokenizes the testing dataset and execute the inference procedure.\n","  \"\"\"\n","\n","  TRAIN_MAX_LEN = 160\n","  TRAIN_BATCH_SIZE = 16\n","  BERT_MODEL = 'bert-base-uncased'\n","\n","  testing_set_path = '/content/drive/My Drive/SentiHood/Bert-pair/NLI-M/Datasets/testing_set.csv'\n","\n","  df_test = pd.read_csv(testing_set_path)\n","  sentiment_mapping = {\n","      'Positive': 0,\n","      'Negative': 1,\n","      'None': 2\n","  }\n","  df_test['sentiment'] = df_test['sentiment'].map(sentiment_mapping)\n","  df_test = df_test.reset_index(drop=True)\n","\n","  tokenizer = transformers.BertTokenizer.from_pretrained(BERT_MODEL)\n","\n","  test_dataset = SentiHood(\n","      opinions_id = df_test['id'].values,\n","      text = df_test['text'].values,\n","      auxiliary_sentence = df_test['auxiliary_sentence'],\n","      targets = df_test['sentiment'].values,\n","      tokenizer = tokenizer,\n","      max_len = TRAIN_MAX_LEN\n","  )\n","  print(f\"Training Set: {len(test_dataset)}\")\n","\n","  test_data_loader = torch.utils.data.DataLoader(\n","      test_dataset,\n","      batch_size = TRAIN_BATCH_SIZE,\n","      shuffle=False\n","  )\n","\n","  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","  print(f\"Device: {device}\")\n","\n","  model = torch.load('/content/drive/My Drive/SentiHood/Bert-pair/NLI-M/Models/best.bin')\n","  infer_loop_function(data_loader=test_data_loader, model=model, device=device)\n","      \n","if __name__ == \"__main__\":\n","  run()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aa09d29845804b6b8f8fd8b5a56a7143","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Training Set: 22548\n","Device: cuda:0\n"],"name":"stdout"},{"output_type":"stream","text":["  7%|██▉                                     | 105/1410 [00:19<04:04,  5.33it/s]"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"qG4vUkDMGtZ6","colab_type":"text"},"source":["# Evaluation of BERT-pair NLI-M"]},{"cell_type":"code","metadata":{"id":"HtYO_f4pGyJY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1596080369995,"user_tz":-330,"elapsed":1444,"user":{"displayName":"NIKHIL PRAKASH","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgE64-zyQNQSjSixENWJyhGqao6rzutp-TYuXNn2Q=s64","userId":"07464489639094286985"}},"outputId":"e2272baf-81c3-46b2-fc81-407092767522"},"source":["def compute_sentiment_accuracy(df):\n","  \"\"\"This function computes the sentiment classfication accuracy\"\"\"\n","  \n","  accuracy = df[df['predicted'] == df['actual']].shape[0]/df.shape[0] * 100\n","  return round(accuracy, 2)\n","\n","df = pd.read_csv('/content/drive/My Drive/SentiHood/Bert-pair/NLI-M/PredictedValues.csv')\n","print(f'Sentiment Accuracy of BERT-pair QA-M = {compute_sentiment_accuracy(df)}%')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sentiment Accuracy of BERT-pair QA-M = 97.28%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"icSi6UoPHLAG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1596080411627,"user_tz":-330,"elapsed":2458,"user":{"displayName":"NIKHIL PRAKASH","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgE64-zyQNQSjSixENWJyhGqao6rzutp-TYuXNn2Q=s64","userId":"07464489639094286985"}},"outputId":"b4d29ef0-14ea-4081-aab4-10ee43adf3d3"},"source":["def compute_aspect_accuracy(df):\n","  \"\"\"\n","  This function computes the strict aspect accuracy.\n","  0 => Represents that the aspect has not been detected.\n","  1 => Represents that the aspect has been detected.\n","  \"\"\"\n","  \n","  df = df.replace([0, 1], 1).replace(2, 0)\n","\n","  count = 0\n","  total = 0\n","\n","  for i in range(0, df.shape[0], 12):\n","    true_values = df.iloc[i:i+12]['predicted']\n","    predicted_values = df.iloc[i:i+12]['actual']\n","\n","    if (true_values == predicted_values).all():\n","      count += 1\n","    total += 1\n","\n","  accuracy = float(count)/float(total)*100\n","  return round(accuracy, 2)\n","\n","df = pd.read_csv('/content/drive/My Drive/SentiHood/Bert-pair/NLI-M/PredictedValues.csv')\n","print(f'Aspect Accuracy (strict) of BERT-pair NLI-M = {compute_aspect_accuracy(df)}%')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Aspect Accuracy (strict) of BERT-pair NLI-M = 74.77%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TzIfR5nxKbv9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1596080425488,"user_tz":-330,"elapsed":3903,"user":{"displayName":"NIKHIL PRAKASH","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgE64-zyQNQSjSixENWJyhGqao6rzutp-TYuXNn2Q=s64","userId":"07464489639094286985"}},"outputId":"ba4df0e1-8f9a-4a5d-afdf-ce0ce69179d5"},"source":["def compute_aspect_f1_score(df):\n","  \"\"\"\n","  This function computest the macro F1 score of predicted aspects.\n","  0 => Represents that the aspect has not been detected.\n","  1 => Represents that the aspect has been detected.\n","  \"\"\"\n","  \n","  df = df.replace([0, 1], 1).replace(2, 0)\n","\n","  total_f1_score = 0\n","  total = 0\n","  \n","  for i in range(0, df.shape[0], 12):\n","    true_values = df.iloc[i:i+12]['predicted']\n","    predicted_values = df.iloc[i:i+12]['actual']\n","\n","    total_f1_score += f1_score(true_values, predicted_values, average=\"macro\")\n","    total += 1\n","\n","  score = float(total_f1_score)/float(total)*100\n","  return round(score, 2)\n","\n","df = pd.read_csv('/content/drive/My Drive/SentiHood/Bert-pair/NLI-M/PredictedValues.csv')\n","print(f\"Aspect F1 score: {compute_aspect_f1_score(df)}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Aspect F1 score: 90.86\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HzING8oSa24-","colab_type":"text"},"source":["# Prediction Result Analysis\n","\n","This section analyses the predicted results to find the aspects and sentiments that are most and least accurate.\n","\n","*Note*: Utilizing the fact that first 1491x12 entries in the loaded `df` are related to `location-1` and rest are related to `location-2`. "]},{"cell_type":"code","metadata":{"id":"TlZzdPaEa7kG","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596462757934,"user_tz":-330,"elapsed":1816,"user":{"displayName":"NIKHIL PRAKASH","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgE64-zyQNQSjSixENWJyhGqao6rzutp-TYuXNn2Q=s64","userId":"07464489639094286985"}}},"source":["df = pd.read_csv('/content/drive/My Drive/SentiHood/Bert-pair/NLI-M/PredictedValues.csv')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"S_FUCBuda7nM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596462775889,"user_tz":-330,"elapsed":19448,"user":{"displayName":"NIKHIL PRAKASH","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgE64-zyQNQSjSixENWJyhGqao6rzutp-TYuXNn2Q=s64","userId":"07464489639094286985"}},"outputId":"3d3c71a4-0cdd-4126-838c-8281a46f5ab0"},"source":["\"\"\"\n","Computes the positive_correct, positive_total, negative_correct, negative_total, \n","none_correct, none_total corresponding to all the aspects of LOCATION1.\n","\"\"\"\n","\n","aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety', 'shopping', 'touristy', 'transit-location']\n","location1_aspects_result_analysis = {}\n","\n","for i in range(12):\n","  location1_aspects_result_analysis[aspects[i]] = [[0 ,0], [0 ,0], [0 ,0]]\n","\n","for i in tqdm(range(0, df['id'].unique().shape[0]*12-12, 12), ncols=80):\n","  for j in range(12):\n","    if df.loc[i+j]['actual'] == df.loc[i+j]['predicted']:\n","      location1_aspects_result_analysis[aspects[j]][int(df.loc[i+j]['actual'])][0] += 1\n","    \n","    location1_aspects_result_analysis[aspects[j]][int(df.loc[i+j]['actual'])][1] += 1"],"execution_count":6,"outputs":[{"output_type":"stream","text":["100%|███████████████████████████████████████| 1490/1490 [00:17<00:00, 82.91it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"DHIz2mkva7hK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596462802909,"user_tz":-330,"elapsed":923,"user":{"displayName":"NIKHIL PRAKASH","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgE64-zyQNQSjSixENWJyhGqao6rzutp-TYuXNn2Q=s64","userId":"07464489639094286985"}}},"source":["df_location_aspect = pd.DataFrame({\"location\": [], \"aspect\": [], \"positive_correct\": [], \"positive_total\": [], \"negative_correct\": [], \"negative_total\": [], \"none_correct\": [], \"none_total\": [],})\n","\n","ii = 0\n","for key in location1_aspects_result_analysis.keys():\n","  df_location_aspect.loc[ii] = ['LOCATION1', f\"{key}\", \n","                                location1_aspects_result_analysis[key][0][0], \n","                                location1_aspects_result_analysis[key][0][1], \n","                                location1_aspects_result_analysis[key][1][0], \n","                                location1_aspects_result_analysis[key][1][1], \n","                                location1_aspects_result_analysis[key][2][0], \n","                                location1_aspects_result_analysis[key][2][1]]\n","  ii += 1"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"iwOBj9eAbg7r","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596462808811,"user_tz":-330,"elapsed":5475,"user":{"displayName":"NIKHIL PRAKASH","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgE64-zyQNQSjSixENWJyhGqao6rzutp-TYuXNn2Q=s64","userId":"07464489639094286985"}},"outputId":"37a25763-183f-4c5e-b4f5-8dba3bbcc750"},"source":["\"\"\"\n","Computes the positive_correct, positive_total, negative_correct, negative_total, \n","none_correct, none_total corresponding to all the aspects of LOCATION2.\n","\"\"\"\n","\n","aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety', 'shopping', 'touristy', 'transit-location']\n","location2_aspects_result_analysis = {}\n","\n","for i in range(12):\n","  location2_aspects_result_analysis[aspects[i]] = [[0 ,0], [0 ,0], [0 ,0]]\n","\n","for i in tqdm(range(df['id'].unique().shape[0]*12, df.shape[0]-12, 12), ncols=80):\n","  for j in range(12):\n","    if df.loc[i+j]['actual'] == df.loc[i+j]['predicted']:\n","      location2_aspects_result_analysis[aspects[j]][int(df.loc[i+j]['actual'])][0] += 1\n","    \n","    location2_aspects_result_analysis[aspects[j]][int(df.loc[i+j]['actual'])][1] += 1"],"execution_count":9,"outputs":[{"output_type":"stream","text":["100%|█████████████████████████████████████████| 387/387 [00:04<00:00, 85.23it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"JqOK-qB5bg40","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596462810336,"user_tz":-330,"elapsed":1519,"user":{"displayName":"NIKHIL PRAKASH","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgE64-zyQNQSjSixENWJyhGqao6rzutp-TYuXNn2Q=s64","userId":"07464489639094286985"}}},"source":["for key in location2_aspects_result_analysis.keys():\n","  df_location_aspect.loc[ii] = ['LOCATION2', f\"{key}\", \n","                                location2_aspects_result_analysis[key][0][0], \n","                                location2_aspects_result_analysis[key][0][1], \n","                                location2_aspects_result_analysis[key][1][0], \n","                                location2_aspects_result_analysis[key][1][1], \n","                                location2_aspects_result_analysis[key][2][0], \n","                                location2_aspects_result_analysis[key][2][1]]\n","  ii += 1"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"VOy4F1tnbg2k","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596462810342,"user_tz":-330,"elapsed":966,"user":{"displayName":"NIKHIL PRAKASH","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgE64-zyQNQSjSixENWJyhGqao6rzutp-TYuXNn2Q=s64","userId":"07464489639094286985"}}},"source":["\"\"\"\n","For every location-aspect pair, consider the percentage of only those sentiments\n","which have more than 10 datapoints in the entire testing set.\n","\"\"\"\n","\n","df_location_aspect['positive_percentage'] = round(df_location_aspect['positive_correct']/df_location_aspect['positive_total']*100, 2)\n","df_location_aspect['negative_percentage'] = round(df_location_aspect['negative_correct']/df_location_aspect['negative_total']*100, 2)\n","df_location_aspect['none_percentage'] = round(df_location_aspect['none_correct']/df_location_aspect['none_total']*100, 2)\n","\n","total_percentage = []\n","for i in range(df_location_aspect.shape[0]):\n","  total = 0\n","  value = 0\n","\n","  positive_total = df_location_aspect.loc[i]['positive_total']\n","  negative_total = df_location_aspect.loc[i]['negative_total']\n","  none_total = df_location_aspect.loc[i]['none_total']\n","\n","  if positive_total > 10:\n","    value += df_location_aspect.loc[i]['positive_percentage']\n","    total += 1\n","  else:\n","    df_location_aspect.loc[i, 'positive_percentage'] = 'NaN'\n","\n","  if negative_total > 10:\n","    value += df_location_aspect.loc[i]['negative_percentage']\n","    total += 1\n","  else:\n","    df_location_aspect.loc[i, 'negative_percentage'] = 'NaN'\n","  \n","  if none_total > 10:\n","    value += df_location_aspect.loc[i]['none_percentage']\n","    total += 1\n","  else:\n","    df_location_aspect.loc[i, 'none_percentage'] = 'NaN'\n","\n","  total_percentage.append(round(float(value)/total, 2))\n","\n","df_location_aspect['total'] = total_percentage"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"nXssXWzMbqtq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":793},"executionInfo":{"status":"ok","timestamp":1596462813161,"user_tz":-330,"elapsed":878,"user":{"displayName":"NIKHIL PRAKASH","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgE64-zyQNQSjSixENWJyhGqao6rzutp-TYuXNn2Q=s64","userId":"07464489639094286985"}},"outputId":"abe3575c-2dd9-4a08-f61d-ca70cceb5181"},"source":["df_location_aspect"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>location</th>\n","      <th>aspect</th>\n","      <th>positive_correct</th>\n","      <th>positive_total</th>\n","      <th>negative_correct</th>\n","      <th>negative_total</th>\n","      <th>none_correct</th>\n","      <th>none_total</th>\n","      <th>positive_percentage</th>\n","      <th>negative_percentage</th>\n","      <th>none_percentage</th>\n","      <th>total</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>LOCATION1</td>\n","      <td>dining</td>\n","      <td>29.0</td>\n","      <td>30.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>1453.0</td>\n","      <td>1458.0</td>\n","      <td>96.67</td>\n","      <td>NaN</td>\n","      <td>99.66</td>\n","      <td>98.16</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>LOCATION1</td>\n","      <td>general</td>\n","      <td>296.0</td>\n","      <td>359.0</td>\n","      <td>80.0</td>\n","      <td>113.0</td>\n","      <td>946.0</td>\n","      <td>1018.0</td>\n","      <td>82.45</td>\n","      <td>70.8</td>\n","      <td>92.93</td>\n","      <td>82.06</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>LOCATION1</td>\n","      <td>green-nature</td>\n","      <td>35.0</td>\n","      <td>40.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1443.0</td>\n","      <td>1450.0</td>\n","      <td>87.5</td>\n","      <td>NaN</td>\n","      <td>99.52</td>\n","      <td>93.51</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>LOCATION1</td>\n","      <td>live</td>\n","      <td>50.0</td>\n","      <td>63.0</td>\n","      <td>14.0</td>\n","      <td>23.0</td>\n","      <td>1375.0</td>\n","      <td>1404.0</td>\n","      <td>79.37</td>\n","      <td>60.87</td>\n","      <td>97.93</td>\n","      <td>79.39</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>LOCATION1</td>\n","      <td>multicultural</td>\n","      <td>31.0</td>\n","      <td>39.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>1444.0</td>\n","      <td>1448.0</td>\n","      <td>79.49</td>\n","      <td>NaN</td>\n","      <td>99.72</td>\n","      <td>89.60</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>LOCATION1</td>\n","      <td>nightlife</td>\n","      <td>57.0</td>\n","      <td>62.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>1413.0</td>\n","      <td>1426.0</td>\n","      <td>91.94</td>\n","      <td>NaN</td>\n","      <td>99.09</td>\n","      <td>95.52</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>LOCATION1</td>\n","      <td>price</td>\n","      <td>69.0</td>\n","      <td>81.0</td>\n","      <td>105.0</td>\n","      <td>116.0</td>\n","      <td>1263.0</td>\n","      <td>1293.0</td>\n","      <td>85.19</td>\n","      <td>90.52</td>\n","      <td>97.68</td>\n","      <td>91.13</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>LOCATION1</td>\n","      <td>quiet</td>\n","      <td>10.0</td>\n","      <td>14.0</td>\n","      <td>12.0</td>\n","      <td>15.0</td>\n","      <td>1458.0</td>\n","      <td>1461.0</td>\n","      <td>71.43</td>\n","      <td>80</td>\n","      <td>99.79</td>\n","      <td>83.74</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>LOCATION1</td>\n","      <td>safety</td>\n","      <td>54.0</td>\n","      <td>61.0</td>\n","      <td>53.0</td>\n","      <td>66.0</td>\n","      <td>1350.0</td>\n","      <td>1363.0</td>\n","      <td>88.52</td>\n","      <td>80.3</td>\n","      <td>99.05</td>\n","      <td>89.29</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>LOCATION1</td>\n","      <td>shopping</td>\n","      <td>58.0</td>\n","      <td>62.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1420.0</td>\n","      <td>1427.0</td>\n","      <td>93.55</td>\n","      <td>NaN</td>\n","      <td>99.51</td>\n","      <td>96.53</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>LOCATION1</td>\n","      <td>touristy</td>\n","      <td>18.0</td>\n","      <td>25.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1456.0</td>\n","      <td>1465.0</td>\n","      <td>72</td>\n","      <td>NaN</td>\n","      <td>99.39</td>\n","      <td>85.69</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>LOCATION1</td>\n","      <td>transit-location</td>\n","      <td>124.0</td>\n","      <td>151.0</td>\n","      <td>22.0</td>\n","      <td>33.0</td>\n","      <td>1264.0</td>\n","      <td>1306.0</td>\n","      <td>82.12</td>\n","      <td>66.67</td>\n","      <td>96.78</td>\n","      <td>81.86</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>LOCATION2</td>\n","      <td>dining</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>380.0</td>\n","      <td>383.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>99.22</td>\n","      <td>99.22</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>LOCATION2</td>\n","      <td>general</td>\n","      <td>70.0</td>\n","      <td>87.0</td>\n","      <td>20.0</td>\n","      <td>26.0</td>\n","      <td>250.0</td>\n","      <td>274.0</td>\n","      <td>80.46</td>\n","      <td>76.92</td>\n","      <td>91.24</td>\n","      <td>82.87</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>LOCATION2</td>\n","      <td>green-nature</td>\n","      <td>6.0</td>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>378.0</td>\n","      <td>380.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>99.47</td>\n","      <td>99.47</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>LOCATION2</td>\n","      <td>live</td>\n","      <td>11.0</td>\n","      <td>14.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>361.0</td>\n","      <td>369.0</td>\n","      <td>78.57</td>\n","      <td>NaN</td>\n","      <td>97.83</td>\n","      <td>88.20</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>LOCATION2</td>\n","      <td>multicultural</td>\n","      <td>6.0</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>377.0</td>\n","      <td>378.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>99.74</td>\n","      <td>99.74</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>LOCATION2</td>\n","      <td>nightlife</td>\n","      <td>12.0</td>\n","      <td>12.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>373.0</td>\n","      <td>375.0</td>\n","      <td>100</td>\n","      <td>NaN</td>\n","      <td>99.47</td>\n","      <td>99.73</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>LOCATION2</td>\n","      <td>price</td>\n","      <td>21.0</td>\n","      <td>27.0</td>\n","      <td>24.0</td>\n","      <td>27.0</td>\n","      <td>323.0</td>\n","      <td>333.0</td>\n","      <td>77.78</td>\n","      <td>88.89</td>\n","      <td>97.00</td>\n","      <td>87.89</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>LOCATION2</td>\n","      <td>quiet</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>379.0</td>\n","      <td>380.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>99.74</td>\n","      <td>99.74</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>LOCATION2</td>\n","      <td>safety</td>\n","      <td>12.0</td>\n","      <td>14.0</td>\n","      <td>12.0</td>\n","      <td>17.0</td>\n","      <td>350.0</td>\n","      <td>356.0</td>\n","      <td>85.71</td>\n","      <td>70.59</td>\n","      <td>98.31</td>\n","      <td>84.87</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>LOCATION2</td>\n","      <td>shopping</td>\n","      <td>14.0</td>\n","      <td>15.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>371.0</td>\n","      <td>372.0</td>\n","      <td>93.33</td>\n","      <td>NaN</td>\n","      <td>99.73</td>\n","      <td>96.53</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>LOCATION2</td>\n","      <td>touristy</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>381.0</td>\n","      <td>382.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>99.74</td>\n","      <td>99.74</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>LOCATION2</td>\n","      <td>transit-location</td>\n","      <td>23.0</td>\n","      <td>29.0</td>\n","      <td>4.0</td>\n","      <td>8.0</td>\n","      <td>335.0</td>\n","      <td>350.0</td>\n","      <td>79.31</td>\n","      <td>NaN</td>\n","      <td>95.71</td>\n","      <td>87.51</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     location            aspect  ...  none_percentage  total\n","0   LOCATION1            dining  ...            99.66  98.16\n","1   LOCATION1           general  ...            92.93  82.06\n","2   LOCATION1      green-nature  ...            99.52  93.51\n","3   LOCATION1              live  ...            97.93  79.39\n","4   LOCATION1     multicultural  ...            99.72  89.60\n","5   LOCATION1         nightlife  ...            99.09  95.52\n","6   LOCATION1             price  ...            97.68  91.13\n","7   LOCATION1             quiet  ...            99.79  83.74\n","8   LOCATION1            safety  ...            99.05  89.29\n","9   LOCATION1          shopping  ...            99.51  96.53\n","10  LOCATION1          touristy  ...            99.39  85.69\n","11  LOCATION1  transit-location  ...            96.78  81.86\n","12  LOCATION2            dining  ...            99.22  99.22\n","13  LOCATION2           general  ...            91.24  82.87\n","14  LOCATION2      green-nature  ...            99.47  99.47\n","15  LOCATION2              live  ...            97.83  88.20\n","16  LOCATION2     multicultural  ...            99.74  99.74\n","17  LOCATION2         nightlife  ...            99.47  99.73\n","18  LOCATION2             price  ...            97.00  87.89\n","19  LOCATION2             quiet  ...            99.74  99.74\n","20  LOCATION2            safety  ...            98.31  84.87\n","21  LOCATION2          shopping  ...            99.73  96.53\n","22  LOCATION2          touristy  ...            99.74  99.74\n","23  LOCATION2  transit-location  ...            95.71  87.51\n","\n","[24 rows x 12 columns]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"hHUu0aX4poUu","colab_type":"text"},"source":["# Creating preds.jsonl\n","\n","This section constructs the `preds.jsonl` file which contains model predictions and original annotations in the following json format.\n","\n","\n","```\n","{\n","  \"opinions\": [\n","    {\n","      \"sentiment\": \"Positive\",\n","      \"aspect\": \"safety\",\n","      \"target_entity\": \"LOCATION1\"\n","    }\n","  ],\n","  \"id\": 153,\n","  \"text\": \" LOCATION1 is in Greater London and is a very safe place\",\n","  \"model_pred\": [\n","    {\n","      \"sentiment\": ...,\n","      \"aspect\": ...,\n","      \"target_entity\":...\n","    },...\n","  ]\n","}\n","```"]},{"cell_type":"code","metadata":{"id":"K-oZVA8x0NT6","colab_type":"code","colab":{}},"source":["with open('/content/drive/My Drive/SentiHood/SentiHood Dataset/sentihood-test.json', 'r') as fp:\n","  testing_set = json.load(fp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jX-rJsL7pxlE","colab_type":"code","colab":{}},"source":["labels_to_sentiment_dict = {\n","    0: 'Positive',\n","    1: 'Negative',\n","    2: 'None'\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FIhf2LtSqCOq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102,"referenced_widgets":["33df444fb9204b16847a62ecc46f9f0d","523ef603903944c99b0aaf28dd51f33e","c7a7bbea4ec541919b389eb2bb984484","6af7380e5b4f4687860c048bfababc35","547375b67e9c4a9dba4aecfb11a92301","2007565108ab4012aae8f98348b0b373","d38aa1b16d1e4eee9faf96235e1d1808","8cfb23cedccb4dca918dd71595b2a464"]},"executionInfo":{"status":"ok","timestamp":1596442765771,"user_tz":-330,"elapsed":339202,"user":{"displayName":"NIKHIL PRAKASH","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgE64-zyQNQSjSixENWJyhGqao6rzutp-TYuXNn2Q=s64","userId":"07464489639094286985"}},"outputId":"d2cb193a-5eca-4ca8-eea4-d0d429d9688a"},"source":["BERT_MODEL = 'bert-base-uncased'\n","MAX_LEN = 160\n","locations = ['LOCATION1', 'LOCATION2']\n","aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety', 'shopping', 'touristy', 'transit-location']\n","\n","tokenizer = transformers.BertTokenizer.from_pretrained(BERT_MODEL)\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Device: {device}\")\n","\n","model = torch.load('/content/drive/My Drive/SentiHood/Bert-pair/NLI-M/Models/best.bin')\n","\n","for each_example in tqdm(testing_set, ncols=80):\n","  id = each_example['id']\n","  text = each_example['text'].strip()\n","\n","  each_example['model_pred'] = []\n","\n","  count_location = 1\n","  for location in locations:\n","    if location in text:\n","      # If \"location\" is present in the text, then utilize the trained model\n","      # to predict the aspects and their corresponding sentiment of the text.\n","\n","      text = text.replace(location, 'location - ' + str(count_location))\n","      \n","      for aspect in aspects:\n","        auxiliary_sentence = f'location - {str(count_location)} - {aspect}'\n","        combined_text = text + ' ' + auxiliary_sentence\n","        \n","        inputs = tokenizer.encode_plus(\n","            combined_text,\n","            add_special_tokens = True,\n","            max_length = MAX_LEN,\n","            pad_to_max_length = True\n","        )\n","        ids = torch.tensor(inputs[\"input_ids\"], dtype=torch.long).unsqueeze(0)\n","        mask = torch.tensor(inputs[\"attention_mask\"], dtype=torch.long).unsqueeze(0)\n","        token_type_ids = torch.tensor(inputs[\"token_type_ids\"], dtype=torch.long).unsqueeze(0)\n","\n","        ids = ids.to(device, dtype=torch.long)\n","        mask = mask.to(device, dtype=torch.long)\n","        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n","\n","        outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n","        _, predicted = torch.max(outputs, 1)\n","\n","        predicted = predicted.detach().cpu().numpy()\n","\n","         # If predicted sentiment is not None, then add it to the preds.jsonl.\n","         \n","        if predicted[0] != 2:\n","          result = {\n","              \"sentiment\": labels_to_sentiment_dict[predicted[0]],\n","              \"aspect\": aspect,\n","              \"target_entity\": location\n","          }\n","          each_example['model_pred'].append(result)\n","      \n","    count_location += 1"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"33df444fb9204b16847a62ecc46f9f0d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Device: cuda:0\n"],"name":"stdout"},{"output_type":"stream","text":["100%|███████████████████████████████████████| 1491/1491 [05:20<00:00,  4.66it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"37Mqdc9uYlCN","colab_type":"code","colab":{}},"source":["with open('/content/drive/My Drive/SentiHood/Bert-pair/NLI-M/pred.jsonl', mode='w', encoding='utf-8') as fp:\n","  for each in testing_set:\n","    json_record = json.dumps(each, ensure_ascii=False)\n","    fp.write(json_record + '\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tha9DXqm5kzE","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}