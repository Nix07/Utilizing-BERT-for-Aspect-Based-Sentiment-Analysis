{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Data Pre-processing New.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nix07/Utilizing-BERT-for-Aspect-Based-Sentiment-Analysis/blob/master/Data_Pre_processing_New.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY79GQATNRqj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "1dddb38d-6c19-4398-ada5-35bca1e0bb01"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf4Bv1DJLUwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "from tqdm import tqdm\n",
        "import pandas as pd"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ-_nYnyLlIi",
        "colab_type": "text"
      },
      "source": [
        "# Preparing Datasets for BERT-single"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WksSYv5sLUwo",
        "colab_type": "text"
      },
      "source": [
        "## Preparing Training Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpNb-FQHLUwq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/SentiHood/Original Data/sentihood-train.json', 'r') as fp:\n",
        "    training_set = json.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4cYyDBTLUxG",
        "colab_type": "code",
        "colab": {},
        "outputId": "89397e3b-c24f-4b0d-e05c-3712a219b166"
      },
      "source": [
        "len(training_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2977"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDcOwcmTLUxZ",
        "colab_type": "code",
        "colab": {},
        "outputId": "e2379feb-6398-4e6b-8628-b48c74eb4577"
      },
      "source": [
        "locations = ['LOCATION1', 'LOCATION2']\n",
        "aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety', 'shopping', 'touristy', 'transit-location']\n",
        "\n",
        "for location in locations:\n",
        "    for aspect in aspects:\n",
        "        df = pd.DataFrame({'id': [], 'text': [], 'sentiment': []})\n",
        "        ii = 0\n",
        "        for each_example in training_set:\n",
        "            id = str(int(each_example['id']))\n",
        "            text = each_example['text'].strip()\n",
        "            \n",
        "            # Add a row only of the \"location\" is present\n",
        "            if location in text:\n",
        "                aspect_found = False\n",
        "                for opinion in each_example['opinions']:\n",
        "                    if opinion['target_entity'] == location and opinion['aspect'] == aspect:\n",
        "                        df.loc[ii] = [id, text, opinion['sentiment']]\n",
        "                        aspect_found = True\n",
        "                        ii += 1\n",
        "                        break\n",
        "                \n",
        "                if not aspect_found:\n",
        "                    df.loc[ii] = [id, text, 'None']\n",
        "                    ii += 1\n",
        "\n",
        "        df.to_csv('/content/drive/My Drive/SentiHood/Bert-single/TrainingData/' + str(location) + str(aspect) + '.csv', index=False)\n",
        "        print(f\"{location}{aspect} DONE!\\tLength = {ii}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LOCATION1dining DONE!\tLength = 2977\n",
            "LOCATION1general DONE!\tLength = 2977\n",
            "LOCATION1green-nature DONE!\tLength = 2977\n",
            "LOCATION1live DONE!\tLength = 2977\n",
            "LOCATION1multicultural DONE!\tLength = 2977\n",
            "LOCATION1nightlife DONE!\tLength = 2977\n",
            "LOCATION1price DONE!\tLength = 2977\n",
            "LOCATION1quiet DONE!\tLength = 2977\n",
            "LOCATION1safety DONE!\tLength = 2977\n",
            "LOCATION1shopping DONE!\tLength = 2977\n",
            "LOCATION1touristy DONE!\tLength = 2977\n",
            "LOCATION1transit-location DONE!\tLength = 2977\n",
            "LOCATION2dining DONE!\tLength = 775\n",
            "LOCATION2general DONE!\tLength = 775\n",
            "LOCATION2green-nature DONE!\tLength = 775\n",
            "LOCATION2live DONE!\tLength = 775\n",
            "LOCATION2multicultural DONE!\tLength = 775\n",
            "LOCATION2nightlife DONE!\tLength = 775\n",
            "LOCATION2price DONE!\tLength = 775\n",
            "LOCATION2quiet DONE!\tLength = 775\n",
            "LOCATION2safety DONE!\tLength = 775\n",
            "LOCATION2shopping DONE!\tLength = 775\n",
            "LOCATION2touristy DONE!\tLength = 775\n",
            "LOCATION2transit-location DONE!\tLength = 775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnJ50OBTLUxi",
        "colab_type": "text"
      },
      "source": [
        "## Preparing Validation Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrXWA9PNLUxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/SentiHood/Original Data/sentihood-dev.json', 'r') as fp:\n",
        "    validation_set = json.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxGJd9PmLUxv",
        "colab_type": "code",
        "colab": {},
        "outputId": "47c29851-ba40-4430-f2fe-f4d62efc7d91"
      },
      "source": [
        "len(validation_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "747"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKoTqGstLUx_",
        "colab_type": "code",
        "colab": {},
        "outputId": "be897877-eb9c-4019-bf80-7cd64277e0b8"
      },
      "source": [
        "locations = ['LOCATION1', 'LOCATION2']\n",
        "aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety', 'shopping', 'touristy', 'transit-location']\n",
        "\n",
        "for location in locations:\n",
        "    for aspect in aspects:\n",
        "        df = pd.DataFrame({'id': [], 'text': [], 'sentiment': []})\n",
        "        ii = 0\n",
        "        for each_example in validation_set:\n",
        "            id = str(int(each_example['id']))\n",
        "            text = each_example['text'].strip()\n",
        "            \n",
        "            # Add a row only of the \"location\" is present\n",
        "            if location in text:\n",
        "                aspect_found = False\n",
        "                for opinion in each_example['opinions']:\n",
        "                    if opinion['target_entity'] == location and opinion['aspect'] == aspect:\n",
        "                        df.loc[ii] = [id, text, opinion['sentiment']]\n",
        "                        aspect_found = True\n",
        "                        ii += 1\n",
        "                        break\n",
        "                \n",
        "                if not aspect_found:\n",
        "                    df.loc[ii] = [id, text, 'None']\n",
        "                    ii += 1\n",
        "\n",
        "        df.to_csv('/content/drive/My Drive/SentiHood/Bert-single/ValidationData/' + str(location) + str(aspect) + '.csv', index=False)\n",
        "        print(f\"{location}{aspect} DONE!\\tLength = {ii}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LOCATION1dining DONE!\tLength = 747\n",
            "LOCATION1general DONE!\tLength = 747\n",
            "LOCATION1green-nature DONE!\tLength = 747\n",
            "LOCATION1live DONE!\tLength = 747\n",
            "LOCATION1multicultural DONE!\tLength = 747\n",
            "LOCATION1nightlife DONE!\tLength = 747\n",
            "LOCATION1price DONE!\tLength = 747\n",
            "LOCATION1quiet DONE!\tLength = 747\n",
            "LOCATION1safety DONE!\tLength = 747\n",
            "LOCATION1shopping DONE!\tLength = 747\n",
            "LOCATION1touristy DONE!\tLength = 747\n",
            "LOCATION1transit-location DONE!\tLength = 747\n",
            "LOCATION2dining DONE!\tLength = 190\n",
            "LOCATION2general DONE!\tLength = 190\n",
            "LOCATION2green-nature DONE!\tLength = 190\n",
            "LOCATION2live DONE!\tLength = 190\n",
            "LOCATION2multicultural DONE!\tLength = 190\n",
            "LOCATION2nightlife DONE!\tLength = 190\n",
            "LOCATION2price DONE!\tLength = 190\n",
            "LOCATION2quiet DONE!\tLength = 190\n",
            "LOCATION2safety DONE!\tLength = 190\n",
            "LOCATION2shopping DONE!\tLength = 190\n",
            "LOCATION2touristy DONE!\tLength = 190\n",
            "LOCATION2transit-location DONE!\tLength = 190\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgspdpzpLqz1",
        "colab_type": "text"
      },
      "source": [
        "# Preparing Datasets for BERT-pair"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg1UnHCjL2rt",
        "colab_type": "text"
      },
      "source": [
        "**Creating Datasets for BERT-pair QA-M**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJMO6XbMLwxG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/SentiHood/Original Data/sentihood-train.json', 'r') as fp:\n",
        "    training_set = json.load(fp)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_DjXpAePMs9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "590e9335-bbbe-463d-e911-ce7b505ce03c"
      },
      "source": [
        "locations = ['LOCATION1', 'LOCATION2']\n",
        "aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety', 'shopping', 'touristy', 'transit-location']\n",
        "\n",
        "df = pd.DataFrame({'id': [], 'text': [], 'auxiliary_sentence': [], 'sentiment': []})\n",
        "ii = 0\n",
        "\n",
        "for location in locations:\n",
        "  for each_example in tqdm(training_set, nols=80):\n",
        "    id = str(int(each_example['id']))\n",
        "    text = each_example['text'].strip()\n",
        "\n",
        "    # Add a row only of the \"location\" is present\n",
        "    if location in text:\n",
        "      current_opinion_aspects = {}\n",
        "      for opinion in each_example['opinions']:\n",
        "        if opinion['target_entity'] == location:\n",
        "          current_opinion_aspects[opinion['aspect']] = opinion['sentiment']\n",
        "      \n",
        "      for aspect in aspects:\n",
        "        auxiliary_sentence = f'what do you think of the {aspect} of {location}?' \n",
        "        if aspect in current_opinion_aspects.keys():\n",
        "          df.loc[ii] = [id, text, auxiliary_sentence, current_opinion_aspects[aspect]]\n",
        "        else:\n",
        "          df.loc[ii] = [id, text, auxiliary_sentence, 'None']\n",
        "        ii += 1\n",
        "          "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2977/2977 [02:23<00:00, 20.78it/s]\n",
            "100%|██████████| 2977/2977 [00:48<00:00, 61.58it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRyqc4nLVbwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df.to_csv('/content/drive/My Drive/SentiHood/Bert-pair/QA-M/training_set.csv', index=False)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQx2iZyjgetn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}