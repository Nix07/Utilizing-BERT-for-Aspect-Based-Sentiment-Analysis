{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InferenceAndEvaluationonSentiHood.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOY6cSYMVo3P/VJPCeRPHUX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nix07/Utilizing-BERT-for-Aspect-Based-Sentiment-Analysis/blob/master/InferenceAndEvaluationonSentiHood.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEZrNmBQD--R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "outputId": "6976637e-f441-4b6d-ad13-37fcf54b8ef8"
      },
      "source": [
        "# Install dependencies\n",
        "!pip uninstall -y tensorflow\n",
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.2.0:\n",
            "  Successfully uninstalled tensorflow-2.2.0\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 4.4MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 23.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 24.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 38.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=213c561070f02cb0284bb96340ec97a72fbf80277660f7a5ff5dbe98711011bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2Tg9H2qFro9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "437ffa6c-d02e-4a4c-d070-30b5267daf8a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXP5sn3DEFJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import transformers\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heq1V0lTx_in",
        "colab_type": "text"
      },
      "source": [
        "# Making Predictions on Testing Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apq1bd74EIds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, BERT_MODEL):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(BERT_MODEL)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, 3) # Number of output classes = 3\n",
        "\n",
        "  def forward(self, ids, mask, token_type_ids, device, tokenizer=None):\n",
        "    last_hidden_state, pooled_output = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids)\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EWrZVNXEUTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentiHood:\n",
        "  def __init__(self, opinions_id, text, targets, tokenizer, max_len):\n",
        "    self.opinions_id = opinions_id\n",
        "    self.text = text\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "    self.targets = targets\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.targets)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    opinions_id = self.opinions_id[item]\n",
        "    text = str(self.text[item])\n",
        "    targets = self.targets[item]\n",
        "\n",
        "    inputs = self.tokenizer.encode_plus(\n",
        "        text,\n",
        "        add_special_tokens = True,\n",
        "        max_length = self.max_len,\n",
        "        pad_to_max_length = True\n",
        "    )\n",
        "\n",
        "    ids = inputs[\"input_ids\"]\n",
        "    mask = inputs[\"attention_mask\"]\n",
        "    token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "    return {\n",
        "        \"ids\": torch.tensor(ids, dtype=torch.long),\n",
        "        \"mask\": torch.tensor(mask, dtype=torch.long),\n",
        "        \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
        "        \"targets\": torch.tensor(targets, dtype=torch.long),\n",
        "        \"opinions_id\": torch.tensor(opinions_id, dtype=torch.long)\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MroNpgUSDC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def infer_loop_function(data_loader, model, device, tokenizer, location, aspect):\n",
        "  model.eval()\n",
        "\n",
        "  df_pred = pd.DataFrame({\"id\": [], \"predicted\": [], \"actual\": []})\n",
        "\n",
        "  ii = 0\n",
        "  for bi, d in tqdm(enumerate(data_loader), total=len(data_loader), ncols=80, leave=False):\n",
        "    opinions_id = d[\"opinions_id\"]\n",
        "    ids = d[\"ids\"]\n",
        "    mask = d[\"mask\"]\n",
        "    token_type_ids = d[\"token_type_ids\"]\n",
        "    targets = d[\"targets\"]\n",
        "\n",
        "    opinions_id = opinions_id.to(device, dtype=torch.long)\n",
        "    ids = ids.to(device, dtype=torch.long)\n",
        "    mask = mask.to(device, dtype=torch.long)\n",
        "    token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "    targets = targets.to(device, dtype=torch.long)\n",
        "\n",
        "    outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids, device=device, tokenizer=tokenizer)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    \n",
        "    predicted = predicted.detach().cpu().numpy()\n",
        "    targets = targets.detach().cpu().numpy()\n",
        "    opinions_id = opinions_id.detach().cpu().numpy()\n",
        "\n",
        "    for k in range(len(predicted)):\n",
        "      df_pred.loc[ii] = [str(opinions_id[k]), str(predicted[k]), str(targets[k])]\n",
        "      ii += 1\n",
        "\n",
        "  print(f\"{location}{aspect} DONE!\")\n",
        "  save_path = '/content/drive/My Drive/SentiHood/TestingData/Predicted' + str(location) + str(aspect) + '.csv'\n",
        "  df_pred.to_csv(save_path, index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IExOxqGGEU1Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "9cc119ba-5ea9-4dee-9d32-8b538308d03f"
      },
      "source": [
        "def run():\n",
        "  MAX_LEN = 140\n",
        "  BATCH_SIZE = 16\n",
        "  BERT_MODEL = 'bert-base-uncased'\n",
        "\n",
        "  locations = ['LOCATION1', 'LOCATION2']\n",
        "  aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety','shopping', 'touristy', 'transit-location']\n",
        "\n",
        "  for location in locations:\n",
        "    for aspect in aspects:\n",
        "      print(f\"Starting {location} {aspect}...\")\n",
        "      testing_set_path = '/content/drive/My Drive/SentiHood/TestingData/' + str(location) + str(aspect) + '.csv'\n",
        "\n",
        "      df_test = pd.read_csv(testing_set_path)\n",
        "      sentiment_mapping = {\n",
        "          'Positive': 0,\n",
        "          'Negative': 1,\n",
        "          'None': 2\n",
        "      }\n",
        "      df_test['sentiment'] = df_test['sentiment'].map(sentiment_mapping)\n",
        "      df_test = df_test.reset_index(drop=True)\n",
        "\n",
        "      tokenizer = transformers.BertTokenizer.from_pretrained(BERT_MODEL)\n",
        "\n",
        "      test_dataset = SentiHood(\n",
        "          opinions_id = df_test['id'].values,\n",
        "          text = df_test['text'].values,\n",
        "          targets = df_test['sentiment'].values,\n",
        "          tokenizer = tokenizer,\n",
        "          max_len = MAX_LEN\n",
        "      )\n",
        "\n",
        "      test_data_loader = torch.utils.data.DataLoader(\n",
        "          test_dataset,\n",
        "          batch_size = BATCH_SIZE,\n",
        "          shuffle = False\n",
        "      )\n",
        "\n",
        "      device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "      print(f\"Device: {device}\")\n",
        "\n",
        "      model = torch.load('/content/drive/My Drive/SentiHood/LocationAspectPairs(NEW)/'+str(location)+str(aspect)+'/best.bin')\n",
        "      infer_loop_function(data_loader=test_data_loader, model=model, device=device, tokenizer=tokenizer, location=location, aspect=aspect)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  run()     "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting LOCATION1 dining...\n",
            "Device: cuda:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOCATION1dining DONE!\n",
            "Starting LOCATION1 general...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Device: cuda:0\n",
            "LOCATION1general DONE!\n",
            "Starting LOCATION1 green-nature...\n",
            "Device: cuda:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOCATION1green-nature DONE!\n",
            "Starting LOCATION1 live...\n",
            "Device: cuda:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOCATION1live DONE!\n",
            "Starting LOCATION1 multicultural...\n",
            "Device: cuda:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOCATION1multicultural DONE!\n",
            "Starting LOCATION1 nightlife...\n",
            "Device: cuda:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOCATION1nightlife DONE!\n",
            "Starting LOCATION1 price...\n",
            "Device: cuda:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 77%|████████████████████████████████▉          | 72/94 [00:23<00:07,  3.12it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FDyDb5McVga",
        "colab_type": "text"
      },
      "source": [
        "#  Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOZIOy_6i3A8",
        "colab_type": "text"
      },
      "source": [
        "### Creating dataframe containing true labels of the testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gGQrWzWdcVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_true_location1 = pd.DataFrame({'id': [], 'location': [] , 'dining': [], 'general': [], 'green-nature': [], 'live': [], 'multicultural': [], 'nightlife': [], 'price': [], 'quiet': [], 'safety': [],'shopping': [], 'touristy': [], 'transit-location': []})\n",
        "aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety','shopping', 'touristy', 'transit-location']\n",
        "\n",
        "for aspect in aspects:\n",
        "  testing_set_path = '/content/drive/My Drive/SentiHood/TestingData/LOCATION1' + str(aspect) + '.csv'\n",
        "\n",
        "  df_test = pd.read_csv(testing_set_path)\n",
        "  sentiment_mapping = {\n",
        "      'Positive': 0,\n",
        "      'Negative': 1,\n",
        "      'None': 2\n",
        "  }\n",
        "  df_test['sentiment'] = df_test['sentiment'].map(sentiment_mapping)\n",
        "  df_test = df_test.reset_index(drop=True)\n",
        "\n",
        "  df_true_location1[aspect] = df_test['sentiment']\n",
        "\n",
        "df_true_location1['location'] = 'LOCATION1'\n",
        "df_true_location1['id'] = df_test['id']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmqC_9F4icS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_true_location2 = pd.DataFrame({'id': [], 'location': [] , 'dining': [], 'general': [], 'green-nature': [], 'live': [], 'multicultural': [], 'nightlife': [], 'price': [], 'quiet': [], 'safety': [],'shopping': [], 'touristy': [], 'transit-location': []})\n",
        "aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety','shopping', 'touristy', 'transit-location']\n",
        "\n",
        "for aspect in aspects:\n",
        "  testing_set_path = '/content/drive/My Drive/SentiHood/TestingData/LOCATION2' + str(aspect) + '.csv'\n",
        "\n",
        "  df_test = pd.read_csv(testing_set_path)\n",
        "  sentiment_mapping = {\n",
        "      'Positive': 0,\n",
        "      'Negative': 1,\n",
        "      'None': 2\n",
        "  }\n",
        "  df_test['sentiment'] = df_test['sentiment'].map(sentiment_mapping)\n",
        "  df_test = df_test.reset_index(drop=True)\n",
        "\n",
        "  df_true_location2[aspect] = df_test['sentiment']\n",
        "\n",
        "df_true_location2['location'] = 'LOCATION2'\n",
        "df_true_location2['id'] = df_test['id']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7uozDz6igHq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "39b0009b-2a20-4bce-8385-40b8fdab20f7"
      },
      "source": [
        "df_true = pd.concat([df_true_location1, df_true_location2])\n",
        "df_true"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>location</th>\n",
              "      <th>dining</th>\n",
              "      <th>general</th>\n",
              "      <th>green-nature</th>\n",
              "      <th>live</th>\n",
              "      <th>multicultural</th>\n",
              "      <th>nightlife</th>\n",
              "      <th>price</th>\n",
              "      <th>quiet</th>\n",
              "      <th>safety</th>\n",
              "      <th>shopping</th>\n",
              "      <th>touristy</th>\n",
              "      <th>transit-location</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>153</td>\n",
              "      <td>LOCATION1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1130</td>\n",
              "      <td>LOCATION1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1271</td>\n",
              "      <td>LOCATION1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1089</td>\n",
              "      <td>LOCATION1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>731</td>\n",
              "      <td>LOCATION1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383</th>\n",
              "      <td>1431</td>\n",
              "      <td>LOCATION2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>384</th>\n",
              "      <td>1290</td>\n",
              "      <td>LOCATION2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>385</th>\n",
              "      <td>363</td>\n",
              "      <td>LOCATION2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>386</th>\n",
              "      <td>1304</td>\n",
              "      <td>LOCATION2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>387</th>\n",
              "      <td>1379</td>\n",
              "      <td>LOCATION2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1879 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       id   location  dining  ...  shopping  touristy  transit-location\n",
              "0     153  LOCATION1       2  ...         2         2                 2\n",
              "1    1130  LOCATION1       2  ...         2         2                 2\n",
              "2    1271  LOCATION1       2  ...         2         2                 2\n",
              "3    1089  LOCATION1       2  ...         2         2                 2\n",
              "4     731  LOCATION1       2  ...         2         2                 2\n",
              "..    ...        ...     ...  ...       ...       ...               ...\n",
              "383  1431  LOCATION2       2  ...         2         2                 2\n",
              "384  1290  LOCATION2       2  ...         2         2                 2\n",
              "385   363  LOCATION2       2  ...         2         2                 2\n",
              "386  1304  LOCATION2       2  ...         2         2                 2\n",
              "387  1379  LOCATION2       2  ...         2         2                 2\n",
              "\n",
              "[1879 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbPOH-qKnMpt",
        "colab_type": "text"
      },
      "source": [
        "### Creating dataframe containing predicted labels of the testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjmSfHgskAuU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_predicted_location1 = pd.DataFrame({'id': [], 'location': [] , 'dining': [], 'general': [], 'green-nature': [], 'live': [], 'multicultural': [], 'nightlife': [], 'price': [], 'quiet': [], 'safety': [],'shopping': [], 'touristy': [], 'transit-location': []})\n",
        "aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety','shopping', 'touristy', 'transit-location']\n",
        "\n",
        "for aspect in aspects:\n",
        "  testing_set_path = '/content/drive/My Drive/SentiHood/PredictedData/PredictedLOCATION1' + str(aspect) + '.csv'\n",
        "\n",
        "  df_test = pd.read_csv(testing_set_path)\n",
        "  df_test = df_test.reset_index(drop=True)\n",
        "\n",
        "  df_predicted_location1[aspect] = df_test['predicted']\n",
        "\n",
        "df_predicted_location1['location'] = 'LOCATION1'\n",
        "df_predicted_location1['id'] = df_test['id']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BZ-c0EZnpez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_predicted_location2 = pd.DataFrame({'id': [], 'location': [] , 'dining': [], 'general': [], 'green-nature': [], 'live': [], 'multicultural': [], 'nightlife': [], 'price': [], 'quiet': [], 'safety': [],'shopping': [], 'touristy': [], 'transit-location': []})\n",
        "aspects = ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety','shopping', 'touristy', 'transit-location']\n",
        "\n",
        "for aspect in aspects:\n",
        "  testing_set_path = '/content/drive/My Drive/SentiHood/PredictedData/PredictedLOCATION2' + str(aspect) + '.csv'\n",
        "\n",
        "  df_test = pd.read_csv(testing_set_path)\n",
        "  df_test = df_test.reset_index(drop=True)\n",
        "\n",
        "  df_predicted_location2[aspect] = df_test['predicted']\n",
        "\n",
        "df_predicted_location2['location'] = 'LOCATION1'\n",
        "df_predicted_location2['id'] = df_test['id']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfaRIGb4oIHx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "602a5139-0ea7-4f6c-b49e-fa60c4621f3a"
      },
      "source": [
        "df_predicted = pd.concat([df_predicted_location1, df_predicted_location2])\n",
        "df_predicted"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>location</th>\n",
              "      <th>dining</th>\n",
              "      <th>general</th>\n",
              "      <th>green-nature</th>\n",
              "      <th>live</th>\n",
              "      <th>multicultural</th>\n",
              "      <th>nightlife</th>\n",
              "      <th>price</th>\n",
              "      <th>quiet</th>\n",
              "      <th>safety</th>\n",
              "      <th>shopping</th>\n",
              "      <th>touristy</th>\n",
              "      <th>transit-location</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>153</td>\n",
              "      <td>LOCATION1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1130</td>\n",
              "      <td>LOCATION1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1271</td>\n",
              "      <td>LOCATION1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1089</td>\n",
              "      <td>LOCATION1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>731</td>\n",
              "      <td>LOCATION1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383</th>\n",
              "      <td>1431</td>\n",
              "      <td>LOCATION1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>384</th>\n",
              "      <td>1290</td>\n",
              "      <td>LOCATION1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>385</th>\n",
              "      <td>363</td>\n",
              "      <td>LOCATION1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>386</th>\n",
              "      <td>1304</td>\n",
              "      <td>LOCATION1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>387</th>\n",
              "      <td>1379</td>\n",
              "      <td>LOCATION1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1879 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       id   location  dining  ...  shopping  touristy  transit-location\n",
              "0     153  LOCATION1       2  ...         2         2                 2\n",
              "1    1130  LOCATION1       2  ...         2         2                 2\n",
              "2    1271  LOCATION1       2  ...         2         2                 2\n",
              "3    1089  LOCATION1       2  ...         2         2                 2\n",
              "4     731  LOCATION1       2  ...         2         0                 2\n",
              "..    ...        ...     ...  ...       ...       ...               ...\n",
              "383  1431  LOCATION1       2  ...         2         2                 2\n",
              "384  1290  LOCATION1       2  ...         2         2                 2\n",
              "385   363  LOCATION1       2  ...         2         2                 2\n",
              "386  1304  LOCATION1       2  ...         2         2                 2\n",
              "387  1379  LOCATION1       2  ...         2         2                 2\n",
              "\n",
              "[1879 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la6Qog6WzOY6",
        "colab_type": "text"
      },
      "source": [
        "**Aspect Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhbY0OqbodLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_aspect_accuracy(df_true, df_predicted):\n",
        "  df_true = df_true.replace([0, 1], 1).replace(2, 0)\n",
        "  df_predicted = df_predicted.replace([0, 1], 1).replace(2, 0)\n",
        "\n",
        "  count = 0\n",
        "  total = 0\n",
        "\n",
        "  for i in range(df_true.shape[0]):\n",
        "    true_values = df_true.iloc[i].values[2:]\n",
        "    predicted_values = df_predicted.iloc[i].values[2:]\n",
        "\n",
        "    if (true_values == predicted_values).all():\n",
        "      count += 1\n",
        "    total += 1\n",
        "\n",
        "  accuracy = float(count)/float(total)*100\n",
        "  return round(accuracy, 2)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31h0xD8Uwf82",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "6796e69a-1370-4104-e5b1-4f624b95afa8"
      },
      "source": [
        "print(f\"Aspect Accuracy (strict): {compute_aspect_accuracy(df_true, df_predicted)}%\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aspect Accuracy (strict): 68.6%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMTW-2QW5qc9",
        "colab_type": "text"
      },
      "source": [
        "**Aspect F1 Score**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf2EzQvr2cKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_aspect_f1_score(df_true, df_predicted):\n",
        "  df_true = df_true.replace([0, 1], 1).replace(2, 0)\n",
        "  df_predicted = df_predicted.replace([0, 1], 1).replace(2, 0)\n",
        "\n",
        "  total_f1_score = 0\n",
        "  total = 0\n",
        "\n",
        "  for i in range(df_true.shape[0]):\n",
        "    true_values = list(df_true.iloc[i].values[2:])\n",
        "    predicted_values = list(df_predicted.iloc[i].values[2:])\n",
        "\n",
        "    total_f1_score += f1_score(true_values, predicted_values, average=\"macro\")\n",
        "    total += 1\n",
        "\n",
        "  score = float(total_f1_score)/float(total)*100\n",
        "  return round(score, 2)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_4l9E3w3GhQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "30f2f619-9d06-4a01-aca8-2732498a8b2c"
      },
      "source": [
        "print(f\"Aspect F1 score: {compute_aspect_f1_score(df_true, df_predicted)}\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aspect F1 score: 88.19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xi3HhPWl9AYY",
        "colab_type": "text"
      },
      "source": [
        "**Sentiment Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nyHEEn12Fax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_sentiment_accuracy(df_true, df_predicted):\n",
        "  \"\"\"3-class Classfication Accuracy\"\"\"\n",
        "\n",
        "  count = 0\n",
        "  total = 0\n",
        "\n",
        "  for aspect in ['dining', 'general', 'green-nature', 'live', 'multicultural', 'nightlife', 'price', 'quiet', 'safety','shopping', 'touristy', 'transit-location']:\n",
        "    count += np.sum(df_true[aspect].values == df_predicted[aspect].values)\n",
        "    total += df_true.shape[0]\n",
        "\n",
        "  accuracy = float(count)/float(total) * 100\n",
        "  return round(accuracy, 2)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssYrZOjq_UOl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "00c5fe00-da00-477e-fce9-cb0a084134c8"
      },
      "source": [
        "print(f\"Sentiment Accuracy: {compute_sentiment_accuracy(df_true, df_predicted)}\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentiment Accuracy: 96.45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK5Fzf4X-nYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}